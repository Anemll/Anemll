#!/usr/bin/env python3
"""
COMPREHENSIVE BIAS SCALING ANALYSIS WITH MATHEMATICAL PROOF

This script demonstrates the bias scaling issue in ANEMLL's per-tensor quantization
and provides the correct mathematical solution.
"""

import os
import torch
import numpy as np
from huggingface_hub import snapshot_download

# Set environment for SP quantization
os.environ['ENABLE_SP_QUANT'] = '1'

def mathematical_analysis():
    """
    Provide mathematical analysis of bias scaling in per-tensor quantization.
    """
    print("="*80)
    print("MATHEMATICAL ANALYSIS OF BIAS SCALING IN PER-TENSOR QUANTIZATION")
    print("="*80)
    
    print("\n1. STANDARD LINEAR LAYER COMPUTATION:")
    print("   y = W * x + b")
    print("   where W = weight matrix, x = input, b = bias vector")
    
    print("\n2. QUANTIZED LINEAR LAYER WITH SEPARATE SCALES:")
    print("   y = (W_stored * input_scale) * x + b_stored * output_scale")
    print("   where:")
    print("     W_stored = quantized weight")
    print("     b_stored = quantized bias")
    print("     input_scale, output_scale = quantization scales")
    
    print("\n3. PRE-MULTIPLIED SCALES (SmoothQuant/QuaRot approach):")
    print("   Storage format:")
    print("     W_stored = W_original * input_scale * output_scale")
    print("     b_stored = b_original * output_scale")
    print("   ")
    print("   To recover original values:")
    print("     W_recover = W_stored / (input_scale * output_scale)")
    print("     b_recover = b_stored / output_scale")
    
    print("\n4. FORWARD PASS WITH RECOVERED VALUES:")
    print("   Method 1 (CORRECT - what should happen):")
    print("     y = W_recover * x + b_recover")
    print("     y = (W_stored / (input_scale * output_scale)) * x + (b_stored / output_scale)")
    print("   ")
    print("   Method 2 (ANEMLL current implementation):")
    print("     y = (W_recover * input_scale) * x + b_recover * output_scale")
    print("     y = ((W_stored / (input_scale * output_scale)) * input_scale) * x + (b_stored / output_scale) * output_scale")
    print("     y = (W_stored / output_scale) * x + b_stored")
    print("   ")
    print("   But ANEMLL currently does NOT scale bias, so:")
    print("     loaded_bias = b_stored (no division by output_scale)")
    print("     y = (W_stored / output_scale) * x + loaded_bias * output_scale")
    print("     y = (W_stored / output_scale) * x + b_stored * output_scale")
    print("   ")
    print("   Since b_stored = b_original * output_scale:")
    print("     y = (W_stored / output_scale) * x + (b_original * output_scale) * output_scale")
    print("     y = (W_stored / output_scale) * x + b_original * output_scale¬≤")
    print("   ")
    print("   üö® BIAS ERROR: bias is scaled by output_scale¬≤ instead of output_scale!")

def demonstrate_bias_scaling_error():
    """
    Demonstrate the bias scaling error with concrete numbers.
    """
    print("\n" + "="*80)
    print("CONCRETE DEMONSTRATION OF BIAS SCALING ERROR")
    print("="*80)
    
    # Example values
    b_original = torch.tensor([1.0, 2.0, 3.0])
    output_scale = torch.tensor([[2.0], [3.0], [4.0]])  # Shape [3, 1] for 3 output features
    
    print(f"Example values:")
    print(f"  b_original = {b_original.tolist()}")
    print(f"  output_scale = {output_scale.squeeze().tolist()}")
    
    # During export/quantization: bias is scaled by output_scale
    b_stored = b_original * output_scale.squeeze()
    print(f"  b_stored = b_original * output_scale = {b_stored.tolist()}")
    
    print(f"\nCorrect loading (what should happen):")
    b_correct = b_stored / output_scale.squeeze()
    print(f"  b_loaded = b_stored / output_scale = {b_correct.tolist()}")
    print(f"  Forward pass: y = W*x + b_loaded * output_scale")
    result_correct = b_correct * output_scale.squeeze()
    print(f"  Bias contribution: {result_correct.tolist()} ‚úì (matches b_original)")
    
    print(f"\nIncorrect loading (ANEMLL current):")
    b_incorrect = b_stored  # No scaling during loading
    print(f"  b_loaded = b_stored = {b_incorrect.tolist()}")
    print(f"  Forward pass: y = W*x + b_loaded * output_scale")
    result_incorrect = b_incorrect * output_scale.squeeze()
    print(f"  Bias contribution: {result_incorrect.tolist()} ‚ùå (wrong!)")
    
    print(f"\nError analysis:")
    error_factor = result_incorrect / b_original
    print(f"  Error factor: {error_factor.tolist()}")
    print(f"  Bias is scaled by output_scale¬≤ instead of output_scale!")

def analyze_real_model_bias_scaling():
    """
    Analyze bias scaling in a real quantized model.
    """
    print("\n" + "="*80)
    print("ANALYSIS OF REAL MODEL BIAS SCALING")
    print("="*80)
    
    try:
        from anemll.models.qwen2_5_model import Qwen25ForCausalLM, Qwen25Config
        from safetensors import safe_open
        
        # Load quantized model
        model_name = "smpanaro/Qwen2.5-0.5B-4bit-PerTensor"
        model_path = snapshot_download(model_name)
        
        # Load safetensors directly to examine stored values
        model_file = f"{model_path}/model.safetensors"
        
        # Pick a specific layer for analysis
        layer_key = "model.layers.0.self_attn.q_proj"
        bias_key = f"{layer_key}.bias"
        output_scale_key = f"{layer_key}.output_scales"
        
        with safe_open(model_file, framework="pt", device="cpu") as f:
            bias_stored = f.get_tensor(bias_key)
            output_scale = f.get_tensor(output_scale_key)
        
        print(f"Analyzing layer: {layer_key}")
        print(f"  Stored bias shape: {bias_stored.shape}")
        print(f"  Output scale shape: {output_scale.shape}")
        print(f"  Bias range: [{bias_stored.min():.6f}, {bias_stored.max():.6f}]")
        print(f"  Scale range: [{output_scale.min():.6f}, {output_scale.max():.6f}]")
        
        # Show what the bias would be after correct vs incorrect loading
        output_scale_flat = output_scale.squeeze(-1)  # [896] shape
        bias_correct = bias_stored / output_scale_flat
        bias_incorrect = bias_stored  # Current ANEMLL approach
        
        print(f"\nBias analysis for first 5 elements:")
        print(f"  Stored bias:     {bias_stored[:5].tolist()}")
        print(f"  Output scale:    {output_scale_flat[:5].tolist()}")
        print(f"  Correct bias:    {bias_correct[:5].tolist()}")
        print(f"  Current bias:    {bias_incorrect[:5].tolist()}")
        
        # In forward pass, bias is multiplied by output_scale again
        print(f"\nForward pass bias contribution (first 5 elements):")
        forward_correct = bias_correct[:5] * output_scale_flat[:5]
        forward_incorrect = bias_incorrect[:5] * output_scale_flat[:5]
        
        print(f"  Correct method:  {forward_correct.tolist()}")
        print(f"  Incorrect method: {forward_incorrect.tolist()}")
        
        # Calculate error
        error_factor = forward_incorrect / forward_correct
        print(f"  Error factor:    {error_factor.tolist()}")
        print(f"  Mean error factor: {error_factor.mean():.4f}")
        
        # Magnitude analysis
        print(f"\nMagnitude analysis:")
        print(f"  Correct bias magnitude (mean): {bias_correct.abs().mean():.6f}")
        print(f"  Current bias magnitude (mean): {bias_incorrect.abs().mean():.6f}")
        print(f"  Magnitude ratio: {(bias_incorrect.abs().mean() / bias_correct.abs().mean()):.4f}")
        
        # Check if this explains the "much bigger error" mentioned in the git commit
        print(f"\nThis explains the 'much bigger error' from git commit 610e36c:")
        print(f"  The bias is scaled by output_scale¬≤ instead of output_scale")
        print(f"  With typical output_scale values around 1.0, this creates significant errors")
        print(f"  The error is proportional to the magnitude of output_scale")
        
        return bias_stored, output_scale, bias_correct, bias_incorrect
        
    except Exception as e:
        print(f"Error analyzing real model: {e}")
        return None, None, None, None

def demonstrate_correct_implementation():
    """
    Show the correct implementation for bias loading in ANEMLL.
    """
    print("\n" + "="*80)
    print("CORRECT IMPLEMENTATION FOR ANEMLL BIAS LOADING")
    print("="*80)
    
    print("Current code in qwen2_5_model.py (lines 1126-1128):")
    print("```python")
    print("# should not scale, scaled on export for SmoothQuant?")
    print("bias_tensor = (v).to(MODEL_DTYPE)  # ‚Üê INCORRECT: not scaling!")
    print("```")
    
    print("\nCorrect implementation:")
    print("```python")
    print("# Correct bias handling: loaded_bias = stored_bias / output_scale") 
    print("# Since bias is added before output scaling in forward pass")
    print("scale = output_scale.to(MODEL_DTYPE)")
    print("if scale.numel() == v.numel():")
    print("    # Same number of elements, reshape to match bias")
    print("    scale = scale.view_as(v)")
    print("elif scale.shape[-1] == 1 and scale.shape[0] == v.shape[0]:")
    print("    # Handle [output_dim, 1] -> [output_dim] case")
    print("    scale = scale.squeeze(-1)")
    print("")
    print("bias_tensor = (v / scale).to(MODEL_DTYPE)  # ‚Üê CORRECT: divide by output_scale")
    print("```")
    
    print("\nMathematical justification:")
    print("1. During export: bias_stored = bias_original * output_scale")
    print("2. During loading: bias_loaded = bias_stored / output_scale")
    print("3. During forward: y = W*x + bias_loaded * output_scale")
    print("4. Result: bias contribution = (bias_stored / output_scale) * output_scale = bias_stored")
    print("5. Since bias_stored = bias_original * output_scale:")
    print("   bias contribution = bias_original * output_scale ‚úì CORRECT")

def create_test_fix():
    """
    Create a test to validate the bias scaling fix.
    """
    print("\n" + "="*80)
    print("TEST TO VALIDATE BIAS SCALING FIX")
    print("="*80)
    
    print("Test case: Simulate the bias loading process")
    
    # Simulate original bias and scale values
    original_bias = torch.tensor([0.1, -0.2, 0.3, -0.4])
    output_scale = torch.tensor([[1.5], [2.0], [0.8], [1.2]])
    
    print(f"Original bias: {original_bias.tolist()}")
    print(f"Output scale: {output_scale.squeeze().tolist()}")
    
    # Simulate what's stored in the safetensors file (bias * output_scale)
    stored_bias = original_bias * output_scale.squeeze()
    print(f"Stored bias (bias * output_scale): {stored_bias.tolist()}")
    
    # Test current ANEMLL loading (incorrect)
    loaded_bias_incorrect = stored_bias
    forward_result_incorrect = loaded_bias_incorrect * output_scale.squeeze()
    print(f"\nCurrent ANEMLL approach:")
    print(f"  Loaded bias: {loaded_bias_incorrect.tolist()}")
    print(f"  Forward result: {forward_result_incorrect.tolist()}")
    print(f"  Error vs original: {(forward_result_incorrect / original_bias).tolist()}")
    
    # Test correct loading (proposed fix)
    loaded_bias_correct = stored_bias / output_scale.squeeze()
    forward_result_correct = loaded_bias_correct * output_scale.squeeze()
    print(f"\nProposed fix:")
    print(f"  Loaded bias: {loaded_bias_correct.tolist()}")
    print(f"  Forward result: {forward_result_correct.tolist()}")
    print(f"  Match original: {torch.allclose(forward_result_correct, original_bias * output_scale.squeeze())}")
    
    print(f"\nValidation:")
    print(f"  Original bias recovered: {torch.allclose(loaded_bias_correct, original_bias)}")
    print(f"  Forward pass correct: {torch.allclose(forward_result_correct, stored_bias)}")

def main():
    """
    Main analysis function.
    """
    print("BIAS SCALING INVESTIGATION IN QUANTIZATION WITH PRE-MULTIPLICATION")
    print("="*80)
    print("This analysis demonstrates the mathematical issue with bias scaling")
    print("in ANEMLL's per-tensor quantization implementation.")
    
    # Mathematical analysis
    mathematical_analysis()
    
    # Concrete demonstration
    demonstrate_bias_scaling_error()
    
    # Real model analysis
    bias_stored, output_scale, bias_correct, bias_incorrect = analyze_real_model_bias_scaling()
    
    # Show correct implementation
    demonstrate_correct_implementation()
    
    # Create test for fix
    create_test_fix()
    
    print("\n" + "="*80)
    print("SUMMARY AND RECOMMENDATIONS")
    print("="*80)
    print("1. PROBLEM IDENTIFIED:")
    print("   - ANEMLL currently loads biases without scaling (line 1128 in qwen2_5_model.py)")
    print("   - This causes bias values to be off by a factor of output_scale")
    print("   - The error compounds in the forward pass, resulting in output_scale¬≤ scaling")
    
    print("\n2. ROOT CAUSE:")
    print("   - Comment suggests bias scaling was disabled for 'SmoothQuant compatibility'")
    print("   - However, the mathematical analysis shows scaling is required for correctness")
    print("   - Pre-multiplied scales require bias to be divided by output_scale during loading")
    
    print("\n3. MATHEMATICAL PROOF:")
    print("   - Export: bias_stored = bias_original * output_scale")
    print("   - Correct loading: bias_loaded = bias_stored / output_scale")
    print("   - Forward pass: result = bias_loaded * output_scale = bias_original * output_scale ‚úì")
    
    print("\n4. PROPOSED FIX:")
    print("   - Uncomment line 1126 in qwen2_5_model.py: bias_tensor = (v / scale).to(MODEL_DTYPE)")
    print("   - Remove line 1128: bias_tensor = (v).to(MODEL_DTYPE)")
    print("   - This will correctly scale biases during loading")
    
    print("\n5. IMPACT:")
    print("   - This fix should resolve the 'much bigger error' mentioned in git commit 610e36c")
    print("   - Bias contributions will be mathematically correct")
    print("   - Quantized model accuracy should improve significantly")
    
    print("\n6. TESTING:")
    print("   - Compare model outputs before and after the fix")
    print("   - Verify bias magnitudes are reasonable after loading")
    print("   - Test with the bias scaling test created above")

if __name__ == "__main__":
    main()